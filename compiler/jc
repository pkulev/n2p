#!/usr/bin/env python3

"""JACK Compiler.

Compiles JACK language to JACK VM language.
"""

import argparse
from collections import namedtuple
import contextlib
import functools
import glob
import itertools
import logging
import os
import re
from xml.sax import saxutils


# --> TOKENIZER

class SyntaxError(Exception):
    """Base class for Jack->VM compilation exceptions."""

    def __init__(self, msg):
        super(SyntaxError, self).__init__(msg)


class UnknownTokenError(SyntaxError):
    """Got unknown token."""

    #def __init__(self, lineno, instruction, args):
    def __init__(self, token):
        super(UnknownTokenError, self).__init__(
            "Unknown token: {0}".format(token))

class TokenNotExpected(SyntaxError):
    """Wrong place for this token."""

    def __init__(self, allowed):
        super(TokenNotExpected, self).__init__(
            "Only next tokens allowed here: {0}".format(allowed))


COMMENT_SYMBOL = "//"

COMMENT           = "commentary"
MULTILINE_COMMENT = "multiline commentary"

BOOLEAN     = "boolean"
CHAR        = "char"
CLASS       = "class"
CONSTRUCTOR = "constructor"
DO          = "do"
ELSE        = "else"
FALSE       = "false"
FIELD       = "field"
FUNCTION    = "function"
IF          = "if"
INT         = "int"
LET         = "let"
METHOD      = "method"
NULL        = "null"
RETURN      = "return"
STATIC      = "static"
THIS        = "this"
TRUE        = "true"
VAR         = "var"
VOID        = "void"
WHILE       = "while"

KEYWORD    = "keyword"
SYMBOL     = "symbol"
INTEGER    = "integer"
STRING     = "string"
IDENTIFIER = "id"
TOKEN      = "token"


KEYWORDS = set((
    CLASS, CONSTRUCTOR, FUNCTION, METHOD, FIELD, STATIC, VAR,
    INT, CHAR, BOOLEAN, VOID, TRUE, FALSE, NULL,
    THIS, LET, DO, IF, ELSE, WHILE, RETURN
))

OPS = ("+" , "-" , "*" , "/" , "&", "|", "<" , ">" , "=")

UNARY_OPS = ("-", "~")

SYMBOLS = set(((
    "{", "}", "(", ")", "[", "]",
    ".", ";", ",",
    ) + OPS + UNARY_OPS
))

_RE_KEYWORD    = r"|".join(KEYWORDS)
_RE_SYMBOL     = "|".join(map(re.escape, SYMBOLS))
_RE_INTEGER    = r"\d+"
_RE_STRING     = r"\"[^\"\n]*\""
_RE_IDENTIFIER = r"[a-zA-Z_][a-zA-Z0-9_]*"
_RE_TOKEN      = r"|".join(
    [_RE_KEYWORD, _RE_SYMBOL, _RE_INTEGER, _RE_STRING, _RE_IDENTIFIER]
)

RE_COMMENT           = re.compile(r"{0}[^\n]*\n".format(COMMENT_SYMBOL))
RE_MULTILINE_COMMENT = re.compile(r"/\*(.*?)\*/", re.MULTILINE | re.DOTALL)
RE_KEYWORD           = re.compile(_RE_KEYWORD)
RE_SYMBOL            = re.compile(_RE_SYMBOL)
RE_INTEGER           = re.compile(_RE_INTEGER)
RE_STRING            = re.compile(_RE_STRING)
RE_IDENTIFIER        = re.compile(_RE_IDENTIFIER)
RE_TOKEN             = re.compile(_RE_TOKEN)


TOKENS = {
    COMMENT:           RE_COMMENT,
    MULTILINE_COMMENT: RE_MULTILINE_COMMENT,
    KEYWORD:           RE_KEYWORD,
    SYMBOL:            RE_SYMBOL,
    INTEGER:           RE_INTEGER,
    STRING:            RE_STRING,
    IDENTIFIER:        RE_IDENTIFIER,
    TOKEN:             RE_TOKEN,  # for check that lexem belongs to JACK lang
}


class Token(object):
    def __init__(self, type_, value):
        self._type = type_
        self.value = value

    def check(self, allowed):
        return self.value in allowed

    def to_xml(self):
        return "<{type}> {value} </{type}>".format(
            type=self._type, value=saxutils.escape(self.value))

    __str__ = to_xml


class Keyword(Token):
    def __init__(self, value):
        if not value in KEYWORDS:
            raise ValueError()
        super(Keyword, self).__init__("keyword", value)


class Symbol(Token):
    def __init__(self, value):
        if not value in SYMBOLS:
            raise Exception()
        super(Symbol, self).__init__("symbol", value)


class Integer(Token):
    def __init__(self, value):
        if not (0 <= int(value) <= (2 ** 15 - 1)):
            raise Exception()
        super(Integer, self).__init__("integerConstant", value)


class String(Token):
    def __init__(self, value):
        if not (value[0] == '"' and value[-1] == '"'):
            raise Exception()
        super(String, self).__init__("stringConstant", value[1:-1])


class Identifier(Token):
    def __init__(self, value):
        super(Identifier, self).__init__("identifier", value)


def is_type(token, source):
    """Check token class.

    :param str token: token class
    :param str source: line of code

    :return: re or None
    """
    return TOKENS[token].match(source)


def strip_comments(sources):
    """Strip comments.

    :param str sources: raw jack code

    :return str: stripped sources without comments
    """

    logging.info("Stripping comments -->")
    sources = RE_COMMENT.sub("", sources)
    sources = RE_MULTILINE_COMMENT.sub("", sources)
    logging.info("Stripping comments <--")
    return sources


def tokenize_line(source):
    errors = 0

    for leftover in TOKENS[TOKEN].split(source):
        if leftover.strip():
            errors += 1
            logging.error("Lexem doesn't belong to JACK: %s", leftover)
    if errors != 0:
        logging.fatal("Total errors: %s", errors)
        raise UnknownTokenError(leftover)

    for token in TOKENS[TOKEN].findall(source):
        if is_type(KEYWORD, token):
            yield Keyword(token)
        elif is_type(SYMBOL, token):
            yield Symbol(token)
        elif is_type(INTEGER, token):
            yield Integer(token)
        elif is_type(STRING, token):
            yield String(token)
        elif is_type(IDENTIFIER, token):
            yield Identifier(token)
        else:
            raise UnknownTokenError(leftover)


def tokenize(sources):
    tokens = []
    for line in strip_comments(sources).splitlines():
        tokens.extend(tokenize_line(line))
    return tokens

def tokens_to_xml(tokens):
    return (
        "<tokens>\n" +
        os.linesep.join(map(Token.to_xml, tokens)) +
        "\n</tokens>\n"
    )

# <-- TOKENIZER

# --> PARSER

def parse(tokens):
    return CompilerEngine(tokens).process()


def check_token(token, type_, *allowed):
    if allowed:
        return isinstance(token, type_) and token.check(allowed)
    return isinstance(token, type_)


def ensure(type_):

    def outer(func):

        @functools.wraps(func)
        def inner(self, *allowed):

            return func(*allowed)

        return inner
    return outer


class CompilerEngine(object):

    def __init__(self, tokens):
        self._tokens = tokens

        self._xml_out = ""
        self._indent = 0
        self._pos = 0

    def process(self):
        self._process_class_declaration()
        if self._pos != len(self._tokens):
            raise SyntaxError("There are leftovers")
        return self._xml_out

    def _xml(self, node):
        indent = "  " * self._indent
        self._xml_out += "{0}{1}\n".format(indent, node)

    def _write_token(self, token):
        self._xml(token.to_xml())
        self._pos += 1

    @contextlib.contextmanager
    def _rule(self, rule):
        try:
            self._xml("<{0}>".format(rule))
            self._indent += 1
            yield
        finally:
            self._indent -= 1
            self._xml("</{0}>".format(rule))

    def _next_token(self):
        return self._tokens[self._pos]

    def _check_next(self, type_, *allowed):
        return check_token(self._next_token(), type_, *allowed)

    def _next_keyword(self, *allowed):
        if not self._check_next(Keyword, *allowed):
            raise TokenNotExpected(repr(allowed))
        self._write_token(self._next_token())

    def _next_symbol(self, *allowed):
        if not self._check_next(Symbol, *allowed):
            raise TokenNotExpected(repr(allowed))
        self._write_token(self._next_token())

    def _next_identifier(self, *allowed):
        if not self._check_next(Identifier, *allowed):
            raise TokenNotExpected(repr(allowed))
        self._write_token(self._next_token())

    def _next_type(self, *allowed):
        token = self._next_token()
        if isinstance(token, Identifier):
            self._next_identifier()
        else:
            self._next_keyword(CHAR, BOOLEAN, INT)

    def _process_class_declaration(self):
        with self._rule("class"):
            self._next_keyword(CLASS)
            self._next_identifier()
            self._next_symbol("{")
            self._next_class_variable_declarations()
            self._next_subroutine_declarations()
            self._next_symbol("}")

    def _next_class_variable_declarations(self):
        while self._check_next(Keyword, FIELD, STATIC):
            self._next_class_variable_declaration()

    def _next_class_variable_declaration(self):
        with self._rule("classVarDec"):
            self._next_keyword(STATIC, FIELD)
            self._next_variable_declaration()

    def _next_variable_declaration(self):
        self._next_type()
        self._next_identifier()

        while not self._check_next(Symbol, ";"):
            self._next_symbol(",")
            self._next_identifier()

        self._next_symbol(";")

    def _next_subroutine_declarations(self):
        while self._check_next(Keyword, CONSTRUCTOR, FUNCTION, METHOD):
            self._next_subroutine_declaration()

    def _next_subroutine_declaration(self):
        with self._rule("subroutineDec"):
            self._next_keyword(CONSTRUCTOR, FUNCTION, METHOD)

            if self._check_next(Keyword, VOID):
                self._next_keyword(VOID)
            else:
                self._next_type()

            self._next_identifier()
            self._next_symbol("(")
            self._next_plist()
            self._next_symbol(")")
            self._next_subroutine_body()

    def _next_plist(self):
        with self._rule("parameterList"):
            first = True
            while not self._check_next(Symbol, ")"):
                if first:
                    first = False
                else:
                    self._next_symbol(",")

                self._next_type()
                self._next_identifier()

    def _next_subroutine_body(self):
        with self._rule("subroutineBody"):
            self._next_symbol("{")
            while self._check_next(Keyword, VAR):
                self._next_subroutine_var_declaration()

            self._next_statements()
            self._next_symbol("}")

    def _next_subroutine_var_declaration(self):
        with self._rule("varDec"):
            self._next_keyword(VAR)
            self._next_variable_declaration()

    def _next_statements(self):
        with self._rule("statements"):
            done = False
            while not done:
                if self._check_next(Keyword, LET):
                    self._next_let_statement()
                elif self._check_next(Keyword, IF):
                    self._next_if_statement()
                elif self._check_next(Keyword, WHILE):
                    self._next_while_statement()
                elif self._check_next(Keyword, DO):
                    self._next_do_statement()
                elif self._check_next(Keyword, RETURN):
                    self._next_return_statement()
                else:
                    done = True

    def _next_let_statement(self):
        with self._rule("letStatement"):
            self._next_keyword(LET)
            self._next_identifier()

            # Array subscription
            if self._check_next(Symbol, "["):
                self._next_symbol("[")
                self._next_expression()
                self._next_symbol("]")

            self._next_symbol("=")
            self._next_expression()
            self._next_symbol(";")

    def _next_if_statement(self):
        with self._rule("ifStatement"):
            self._next_keyword(IF)
            self._next_symbol("(")
            self._next_expression()
            self._next_symbol(")")
            self._next_symbol("{")
            self._next_statements()
            self._next_symbol("}")

            # Else branch
            if self._check_next(Keyword, ELSE):
                self._next_keyword(ELSE)
                self._next_symbol("{")
                self._next_statements()
                self._next_symbol("}")

    def _next_while_statement(self):
        with self._rule("whileStatement"):
            self._next_keyword(WHILE)
            self._next_symbol("(")
            self._next_expression()
            self._next_symbol(")")
            self._next_symbol("{")
            self._next_statements()
            self._next_symbol("}")

    def _next_do_statement(self):
        with self._rule("doStatement"):
            self._next_keyword(DO)
            self._next_subroutine_call()
            self._next_symbol(";")

    def _next_subroutine_call(self):
        self._next_identifier()
        if self._check_next(Symbol, "."):
            self._next_symbol(".")
            self._next_identifier()

        self._next_symbol("(")
        self._next_expression_list()
        self._next_symbol(")")

    def _next_return_statement(self):
        with self._rule("returnStatement"):
            self._next_keyword(RETURN)
            if not self._check_next(Symbol, ";"):
                self._next_expression()
            self._next_symbol(";")

    def _next_expression(self):
        with self._rule("expression"):
            self._expand_term()

            if self._check_next(Symbol, *tuple(OPS)):
                self._next_symbol(*tuple(OPS))
                self._expand_term()

    def _next_expression_list(self):
        with self._rule("expressionList"):
            first = True
            while not self._check_next(Symbol, ")"):
                if first:
                    first = False
                else:
                    self._next_symbol(",")
                self._next_expression()

    def _expand_term(self):
        with self._rule("term"):
            token = self._next_token()

            # integer or string constant
            if isinstance(token, (Integer, String)):
                return self._write_token(token)

            # keyword constants
            elif isinstance(token, Keyword):
                return self._next_keyword(TRUE, FALSE, NULL, THIS)

            # array subscription
            elif self._look_ahead_array_subscr():
                self._next_identifier()
                self._next_symbol("[")
                self._next_expression()
                self._next_symbol("]")

            # subroutine call
            elif self._look_ahead_subroutine_call():
                self._next_subroutine_call()

            # variable
            elif isinstance(token, Identifier):
                self._next_identifier()

            # (expression)
            elif self._check_next(Symbol, "("):
                self._next_symbol("(")
                self._next_expression()
                self._next_symbol(")")

            # unary operations
            elif self._check_next(Symbol, *tuple(UNARY_OPS)):
                self._next_symbol(*tuple(UNARY_OPS))
                self._expand_term()

            else:
                raise UnknownTokenError("token totally unexpected")

    def _look_ahead_array_subscr(self):
        if self._pos + 1 < len(self._tokens):
            token = self._tokens[self._pos + 1]
            return (
                self._check_next(Identifier) and
                check_token(token, Symbol, "["))

    def _look_ahead_subroutine_call(self):
        if self._pos + 1 < len(self._tokens):
            token = self._tokens[self._pos + 1 ]
            return (
                self._check_next(Identifier) and (
                    check_token(token, Symbol, "(") or
                    check_token(token, Symbol, ".")))

# <-- PARSER


def parse_args():
    """Parse and return incoming arguments.

    :return: parsed arguments
    :rtype: argparse.Namespace
    """
    parser = argparse.ArgumentParser(description="JACK VM translator")
    parser.add_argument("-d", "--debug", action="store_true", help="Debug mode")
    parser.add_argument("-o", "--output", help="output file")
    parser.add_argument(
        "-m", "--outmode", default="vm", choices=("xml", "vm"),
        help="Output mode")
    parser.add_argument("filename", help="input file")

    return parser.parse_args()


def main():
    """Main entry point."""

    def chext(filepath, ext):
        path, name = os.path.split(filepath)
        return os.path.join(path, os.path.splitext(name)[0] + ext)

    args = parse_args()
    debug = args.debug

    logging.getLogger().setLevel(logging.DEBUG if debug else logging.INFO)
    logging.debug("Incoming args: %s", args)

    if os.path.isdir(args.filename):
        logging.debug("Compiling directory: %s", args.filename)
        inputs = glob.glob(os.path.join(args.filename, "*jack"))
    else:
        inputs = [args.filename]

    for filename in inputs:
        logging.debug("Compiling file: %s", filename)
        with open(filename) as source:
            tokens = tokenize(source.read())
            bytecode = compile_bytecode(tokens, args.outmode)

        with open(chext(filename, ".{0}".format(args.outmode)), "w") as target:
            target.write(bytecode)


if __name__ == "__main__":
    main()
